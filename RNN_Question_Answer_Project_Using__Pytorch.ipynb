{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-qBaBnbZ3nWO",
        "outputId": "5c9a6d5e-30c1-4118-9a05-874dbface719"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nName   : Rupesh Garsondiya\\ngtihub : @Rupeshgarsondiya\\nTpoic  : Tpoic Recurrent Neural Network (RNN) Using PyTorch\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "'''\n",
        "Name   : Rupesh Garsondiya\n",
        "gtihub : @Rupeshgarsondiya\n",
        "Tpoic  : Tpoic Recurrent Neural Network (RNN) Using PyTorch\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required library\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        ""
      ],
      "metadata": {
        "id": "8Ntnh09R8d2x"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "df = pd.read_csv('/content/100_Unique_QA_Dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0-qTTj_i4dlW",
        "outputId": "e3a1c308-a8d5-4479-d54a-2832f372f8cb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-061dff9a-0f0f-4834-a1ad-a3c5ba21b8ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-061dff9a-0f0f-4834-a1ad-a3c5ba21b8ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-061dff9a-0f0f-4834-a1ad-a3c5ba21b8ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-061dff9a-0f0f-4834-a1ad-a3c5ba21b8ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0243aa9-d2f2-4526-8e85-02b59b9e5c50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0243aa9-d2f2-4526-8e85-02b59b9e5c50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0243aa9-d2f2-4526-8e85-02b59b9e5c50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization of the dataset**"
      ],
      "metadata": {
        "id": "6mpi1HANjaKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Tokenizes a given text by converting it to lowercase,\n",
        "    removing specific punctuation ('?' and \"'\"),\n",
        "    and splitting it into a list of words.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string to be tokenized.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of words from the processed text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove question marks\n",
        "    text = text.replace(\"?\", \"\")\n",
        "\n",
        "    # Remove apostrophes\n",
        "    text = text.replace(\"'\", \"\")\n",
        "\n",
        "    # Split text into a list of words and return\n",
        "    return text.split()\n"
      ],
      "metadata": {
        "id": "ympI0N9I4lJs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(df['question'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMrFYMA5Pfv",
        "outputId": "27307015-a658-4b93-83e9-39a2100a5cc7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a vocablaory**"
      ],
      "metadata": {
        "id": "0w3x4UhhjfKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the vocabulary dictionary with a special token for unknown words\n",
        "vocab = {'<UNK>': 0}\n",
        "\n",
        "def build_vocab(raw):\n",
        "    \"\"\"\n",
        "    Builds a vocabulary dictionary from the given raw text data.\n",
        "\n",
        "    Args:\n",
        "        raw (dict): A dictionary containing 'question' and 'answer' keys,\n",
        "                    where values are text strings.\n",
        "\n",
        "    Returns:\n",
        "        None: Updates the global vocab dictionary in place.\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize the question and answer\n",
        "    tokenized_question = tokenize(raw['question'])\n",
        "    tokenized_answer = tokenize(raw['answer'])\n",
        "\n",
        "    # Merge tokens from both question and answer\n",
        "    merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "    # Add new tokens to the vocabulary\n",
        "    for token in merged_tokens:\n",
        "        if token not in vocab:\n",
        "            vocab[token] = len(vocab)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IHp4TpVW4ouC"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "collapsed": true,
        "id": "oY7uafQN69pf",
        "outputId": "37de78ae-569b-40b5-f0ba-67f3e9cf987c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('='*20,'Vocab','='*20)\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rmbQJH5C6olO",
        "outputId": "cbb9a931-754b-44fe-8ca1-f095e1bf1ae0"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== Vocab ====================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert words in a text to their corresponding numerical indices based on a given vocabulary.\n",
        "\n",
        "def text_to_indices(text, vocab):\n",
        "    \"\"\"\n",
        "    Converts a given text into a list of numerical indices using a provided vocabulary.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be tokenized and converted.\n",
        "        vocab (dict): A dictionary mapping words to their corresponding indices.\n",
        "                      It should contain a special token '<UNK>' for unknown words.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of numerical indices representing the words in the text.\n",
        "    \"\"\"\n",
        "\n",
        "    indexed_text = []  # List to store the numerical indices of words in the text.\n",
        "\n",
        "    for token in tokenize(text):  # Tokenize the input text.\n",
        "        if token in vocab:  # Check if the token exists in the vocabulary.\n",
        "            indexed_text.append(vocab[token])  # Append the corresponding index.\n",
        "        else:\n",
        "            indexed_text.append(vocab['<UNK>'])  # Use '<UNK>' index for unknown words.\n",
        "\n",
        "    return indexed_text  # Return the list of numerical indices.\n"
      ],
      "metadata": {
        "id": "7kR5dCHU4qpU"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices('how are you',vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGDyWtr34wMt",
        "outputId": "068cd313-78ed-4543-fcae-806d5a8b39cb"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[78, 81, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloader class**"
      ],
      "metadata": {
        "id": "J_nPtpZQkJvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class QADataset(Dataset):\n",
        "    \"\"\"\n",
        "    A custom PyTorch dataset for handling Question-Answer pairs.\n",
        "\n",
        "    Attributes:\n",
        "        df (pd.DataFrame): DataFrame containing questions and answers.\n",
        "        vocab (dict): A dictionary mapping words to their corresponding indices.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, vocab):\n",
        "        \"\"\"\n",
        "        Initializes the QADataset with a DataFrame and a vocabulary dictionary.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): A DataFrame containing 'question' and 'answer' columns.\n",
        "            vocab (dict): A dictionary mapping words to indices for numerical representation.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of samples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of rows in the DataFrame.\n",
        "        \"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Retrieves the numerical representation of a question-answer pair at the given index.\n",
        "\n",
        "        Args:\n",
        "            index (int): The index of the sample to fetch.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing:\n",
        "                - torch.Tensor: Numerical representation of the question.\n",
        "                - torch.Tensor: Numerical representation of the answer.\n",
        "        \"\"\"\n",
        "        numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "        numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "\n",
        "        return torch.tensor(numerical_question), torch.tensor(numerical_answer)\n",
        "\n",
        "# Potential issue:\n",
        "# The code snippet contains an extra segment after `return indexed_text`,\n",
        "# which seems to be misplaced. Ensure the function text_to_indices is defined properly.\n"
      ],
      "metadata": {
        "id": "UGks-49l7jQD"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df,vocab)\n",
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzsGZvAA-RNg",
        "outputId": "5fd25393-5469-4721-fcda-b586e97df83e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset,batch_size=1,shuffle=True) # if we use more than one batch then we need to use the padding beacuse length of the word is the diffrent"
      ],
      "metadata": {
        "id": "jOyb9vkJ-ZFD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question, answer in dataloader:\n",
        "\n",
        "  print(question,answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5415yZwz-0Kn",
        "outputId": "1e9b1337-0c03-4f2e-c1bf-5501a94f7422"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
            "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
            "tensor([[10, 75, 76]]) tensor([[77]])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Architechture**"
      ],
      "metadata": {
        "id": "WWIkC86D_uDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A Simple Recurrent Neural Network (RNN) model for text processing.\n",
        "\n",
        "    This model consists of an embedding layer, an RNN layer, and a fully connected layer.\n",
        "    The output of the model is logits, which can be converted to probabilities using softmax.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        \"\"\"\n",
        "        Initializes the SimpleRNN model.\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): The size of the vocabulary.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "        self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "        self.fc = nn.Linear(64, vocab_size)  # Output layer mapping to vocabulary size\n",
        "\n",
        "        # Note: The final Linear layer outputs raw logits.\n",
        "        # To get probabilities, apply softmax activation externally.\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of token indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Logits for each token in the vocabulary.\n",
        "        \"\"\"\n",
        "        embedded_question = self.embedding(x)  # Convert input indices to embeddings\n",
        "\n",
        "        hidden, final = self.rnn(embedded_question)\n",
        "        output = self.fc(final.squeeze(0))\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Retrieves a numerical representation of a question-answer pair.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the question-answer pair.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (tensor of numerical question, tensor of numerical answer)\n",
        "        \"\"\"\n",
        "        numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "        numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "\n",
        "        return torch.tensor(numerical_question), torch.tensor(numerical_answer)\n",
        "\n",
        "\n",
        "def text_to_indices(text, vocab):\n",
        "    \"\"\"\n",
        "    Converts a text string into a list of numerical indices based on the vocabulary.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to convert.\n",
        "        vocab (dict): A dictionary mapping words to indices.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of indices representing the text.\n",
        "    \"\"\"\n",
        "    indexed_text = []\n",
        "    for token in text.split():\n",
        "        if token in vocab:\n",
        "            indexed_text.append(vocab[token])\n",
        "        else:\n",
        "            indexed_text.append(vocab['<UNK>'])  # Use <UNK> for unknown words\n",
        "\n",
        "    return indexed_text\n"
      ],
      "metadata": {
        "id": "2hqUib7__Gf5"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZEWl96jAgyk",
        "outputId": "66ee27bb-f562-464a-cb01-23a727729dcb"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  2,  3, 69,  5,  3,  0,  0]), tensor([0]))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = nn.Embedding(324,embedding_dim=50)\n",
        "a = e(dataset[0][0])"
      ],
      "metadata": {
        "id": "jMtxAXB8Ai82"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50,64)"
      ],
      "metadata": {
        "id": "PqBr4qJOA9vd"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This script prints the hidden state output shape and values from a network.\n",
        "It manually executes the forward pass and does not use a Sequential container\n",
        "due to the feedback nature of the network.\n",
        "\n",
        "Key Observations:\n",
        "- The output consists of two parts: hidden state and the final output.\n",
        "- The last hidden state and the final output are the same.\n",
        "\"\"\"\n",
        "\n",
        "# Print the shape of the hidden state output\n",
        "print('=' * 27, ' Hidden State Output Shape ', '=' * 27)\n",
        "print(y(a)[0].shape)  # First element of the output (tuple), representing hidden state shape\n",
        "print('=' * 30, ' Hidden State Output Shape ', '=' * 25)\n",
        "print(y(a)[1].shape)  # Second element of the output, representing the final output shape\n",
        "\n",
        "# Print the hidden state output values\n",
        "print('=' * 30, ' Hidden State Output ', '=' * 30)\n",
        "print(y(a)[0])  # Hidden state output values\n",
        "print('=' * 20, ' Hidden State Output ', '=' * 27)\n",
        "output = y(a)[1]  # Storing the final output\n",
        "output  # Displaying the final output\n",
        "\n",
        "# Notes:\n",
        "# - The feedback nature of this network requires manually writing the forward pass.\n",
        "# - We do not use a Sequential container for this architecture.\n",
        "# - The output of the last hidden layer and the final output are the same.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qFsJKWzBgKF",
        "outputId": "ad642adb-7ea8-4444-b4a1-49abe85d8e76"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================  Hidden State Output Shape  ===========================\n",
            "torch.Size([6, 64])\n",
            "==============================  Hidden State Output Shape  =========================\n",
            "torch.Size([1, 64])\n",
            "==============================  Hidden State Output  ==============================\n",
            "tensor([[-1.1723e-01,  3.3080e-02, -5.7309e-02,  5.4739e-01, -1.7886e-01,\n",
            "          1.8129e-02, -8.1863e-03, -1.1049e-01, -5.7209e-01, -5.7035e-01,\n",
            "         -4.6142e-01, -6.4173e-02,  2.4251e-01, -2.8623e-01,  1.3863e-01,\n",
            "          3.8866e-02,  6.0703e-01, -1.8687e-01, -1.4840e-01,  4.2552e-01,\n",
            "         -7.1063e-01,  7.8312e-01,  2.2086e-01,  5.2961e-01, -2.3210e-01,\n",
            "          4.6716e-03,  4.0326e-01, -1.9379e-01, -5.6440e-01,  4.5493e-01,\n",
            "          2.2584e-01,  9.4899e-02,  4.4309e-01,  1.2270e-01, -3.6648e-01,\n",
            "         -3.1713e-01,  6.8412e-02,  7.6928e-02, -6.0199e-01,  5.1746e-01,\n",
            "         -5.3260e-03,  8.1868e-01, -3.8868e-01, -1.8287e-01,  6.6645e-02,\n",
            "         -5.9755e-02,  1.9545e-01,  2.5647e-01, -2.1768e-01, -1.9044e-01,\n",
            "          4.7257e-01, -5.3656e-02,  4.6672e-01, -1.8141e-01, -1.8896e-01,\n",
            "          2.3128e-01,  8.8005e-04, -1.4929e-01,  4.4917e-01, -4.9151e-01,\n",
            "          7.5251e-01,  3.2529e-01,  5.0826e-01, -4.8637e-02],\n",
            "        [-5.6083e-01,  3.7209e-02,  1.8246e-01,  7.0999e-01, -5.0397e-01,\n",
            "         -5.6270e-01,  7.1209e-01, -5.7876e-01, -7.9463e-01, -7.8423e-01,\n",
            "          1.5418e-01,  4.0331e-02,  1.9940e-01, -6.4915e-02, -1.7882e-02,\n",
            "         -6.7106e-01, -1.9735e-01, -3.3985e-01,  4.1463e-01,  1.4736e-01,\n",
            "          9.8260e-02,  8.8533e-01, -4.6625e-01,  3.9815e-01, -5.6169e-01,\n",
            "          5.2729e-01,  1.1870e-01, -5.0984e-01,  1.3858e-01,  4.7127e-01,\n",
            "         -4.5311e-01,  5.7740e-01,  2.2717e-01,  1.9569e-02, -2.5261e-01,\n",
            "          8.8190e-02,  6.2428e-01, -3.2230e-01, -6.1604e-01, -2.3747e-01,\n",
            "          1.6961e-02,  2.3844e-01,  4.1467e-01,  3.5584e-01, -2.6111e-01,\n",
            "         -3.3016e-01,  7.7088e-01,  1.5965e-01, -4.4985e-01, -7.5314e-01,\n",
            "         -3.6903e-01,  7.1084e-01,  3.1411e-01, -9.4926e-02,  6.5246e-01,\n",
            "          2.3009e-01, -1.6806e-02, -6.6675e-01,  8.4148e-02, -6.3078e-01,\n",
            "          4.0339e-01,  3.0756e-01, -3.6404e-01,  3.6400e-01],\n",
            "        [-2.1790e-01,  4.3769e-02, -3.0059e-01, -6.9055e-01, -2.2770e-01,\n",
            "          9.1709e-02,  1.0886e-01,  1.5804e-01,  4.9668e-01,  2.4788e-01,\n",
            "          7.6783e-01,  1.5166e-01,  4.2349e-01,  3.5993e-01,  5.4835e-01,\n",
            "         -1.3231e-01, -2.1068e-01, -5.4728e-01, -6.8655e-01, -4.9385e-01,\n",
            "          3.7882e-01,  1.3556e-01,  1.3983e-01, -4.7048e-01,  5.7862e-01,\n",
            "         -5.1910e-01, -3.4364e-01,  9.7235e-03, -3.8055e-02, -6.3439e-01,\n",
            "          4.2376e-01,  5.4544e-03,  2.2315e-01,  3.4619e-01,  6.9403e-01,\n",
            "          4.9184e-01, -7.9852e-01, -2.3680e-01,  4.7714e-01,  6.6037e-01,\n",
            "          3.5939e-01, -4.0719e-01, -3.4122e-01,  4.4267e-01,  1.9265e-01,\n",
            "         -3.3763e-01,  6.6344e-01, -2.7115e-01, -2.4324e-01,  2.1108e-01,\n",
            "         -9.1960e-02, -3.6105e-01, -7.4170e-01, -2.8921e-01,  5.0382e-01,\n",
            "          4.6309e-01,  8.1565e-01,  2.9617e-01,  4.1377e-01, -5.4601e-01,\n",
            "         -4.9700e-01, -1.1096e-01,  8.8796e-01, -7.2766e-01],\n",
            "        [ 6.7644e-01,  2.6413e-01, -8.5477e-01,  8.3525e-01, -7.6850e-01,\n",
            "         -1.2114e-01,  6.3336e-01,  3.7287e-01, -6.4199e-01, -1.0557e-01,\n",
            "         -6.3790e-01,  7.8237e-01,  2.5451e-01, -7.4572e-01, -2.9795e-01,\n",
            "          4.9541e-01,  6.2655e-01,  4.1612e-01,  4.4777e-01,  5.8234e-01,\n",
            "         -6.2331e-01, -1.6657e-01,  3.8959e-01,  1.4456e-01,  3.9447e-03,\n",
            "         -5.1440e-01,  2.1646e-01, -5.8215e-01,  1.1753e-01, -2.8985e-01,\n",
            "         -6.0564e-01,  2.5881e-01,  6.6880e-02,  6.3498e-01,  3.8843e-01,\n",
            "          1.0740e-01,  8.3174e-01,  7.9103e-01,  6.7282e-01, -1.2780e-01,\n",
            "         -5.1906e-01,  2.7801e-01, -6.3505e-01, -4.5913e-01,  6.8119e-01,\n",
            "          4.3989e-01,  1.3687e-01, -4.9916e-01,  5.5469e-01,  8.9051e-01,\n",
            "         -5.9767e-01,  5.3887e-02,  1.1330e-01, -9.1342e-02, -6.3362e-01,\n",
            "         -4.7640e-01,  4.9659e-01,  4.6747e-01, -1.4401e-01,  4.9439e-01,\n",
            "          4.2315e-02, -8.6819e-01, -1.9541e-01, -3.0559e-01],\n",
            "        [ 4.8576e-01, -4.8133e-01,  1.8015e-01, -5.7487e-01, -6.9290e-01,\n",
            "          3.8851e-01,  7.5462e-01, -3.7664e-02, -3.2004e-02, -2.6295e-01,\n",
            "          3.0754e-01, -9.3409e-01,  7.5478e-01,  2.4531e-01,  4.7162e-01,\n",
            "          8.3456e-01,  4.9105e-01, -4.7016e-01,  5.7655e-01, -8.6095e-01,\n",
            "          7.2311e-01, -8.1855e-01,  6.8520e-01, -4.3431e-01,  5.7501e-01,\n",
            "          3.5763e-01, -3.9545e-01,  4.0540e-01,  3.3480e-02,  7.4917e-01,\n",
            "          4.3035e-02, -1.3789e-01, -4.5971e-01, -2.3816e-01,  6.5292e-01,\n",
            "         -2.8247e-02, -2.1790e-01, -6.2774e-01, -4.2073e-01,  4.8655e-01,\n",
            "          6.4210e-01, -6.6737e-01, -4.6066e-01,  8.5630e-01, -1.5334e-01,\n",
            "         -3.3176e-01, -8.1694e-01, -4.6633e-01,  9.4653e-02, -1.9647e-01,\n",
            "         -1.4882e-01, -7.4640e-01, -3.4595e-01,  7.6464e-01, -4.9469e-01,\n",
            "          5.4787e-01, -6.2130e-02, -1.6202e-01,  6.9962e-01,  1.9462e-01,\n",
            "          3.5118e-01,  1.7677e-01,  3.0555e-01,  8.3827e-01],\n",
            "        [-6.6258e-01, -1.0523e-02, -5.4329e-02,  1.7084e-01,  1.4353e-01,\n",
            "         -1.4213e-01, -2.1834e-01, -1.5291e-03, -4.0637e-01, -4.9720e-01,\n",
            "         -7.7535e-01, -1.4031e-01,  8.8552e-02, -6.0485e-01, -1.8132e-01,\n",
            "         -4.1052e-01,  4.3161e-01, -4.8470e-01, -2.3125e-01,  2.8662e-01,\n",
            "         -5.7368e-01,  7.0196e-01,  3.5302e-01,  4.8021e-01,  2.6472e-01,\n",
            "         -4.5697e-02,  6.6119e-01, -5.0825e-01, -5.4378e-01, -1.4227e-01,\n",
            "         -5.4155e-01, -8.9554e-02,  6.9757e-01, -1.8852e-01, -4.4119e-01,\n",
            "         -4.2813e-01,  3.6325e-01,  7.7364e-02, -3.2579e-01,  4.9783e-01,\n",
            "         -1.3531e-01,  7.2286e-01, -4.4913e-01,  7.9783e-02,  1.5722e-01,\n",
            "          2.1712e-01, -3.7410e-03,  4.2779e-01, -3.7894e-01,  2.9308e-01,\n",
            "          4.8273e-02,  1.3244e-01,  5.5774e-01, -1.9466e-01,  4.6657e-01,\n",
            "         -6.0008e-02,  7.8410e-02, -1.8279e-01,  6.2047e-01, -3.1402e-01,\n",
            "          8.4500e-01,  5.4428e-01,  6.4138e-01,  1.6179e-01]],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "====================  Hidden State Output  ===========================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6626, -0.0105, -0.0543,  0.1708,  0.1435, -0.1421, -0.2183, -0.0015,\n",
              "         -0.4064, -0.4972, -0.7753, -0.1403,  0.0886, -0.6049, -0.1813, -0.4105,\n",
              "          0.4316, -0.4847, -0.2312,  0.2866, -0.5737,  0.7020,  0.3530,  0.4802,\n",
              "          0.2647, -0.0457,  0.6612, -0.5083, -0.5438, -0.1423, -0.5416, -0.0896,\n",
              "          0.6976, -0.1885, -0.4412, -0.4281,  0.3632,  0.0774, -0.3258,  0.4978,\n",
              "         -0.1353,  0.7229, -0.4491,  0.0798,  0.1572,  0.2171, -0.0037,  0.4278,\n",
              "         -0.3789,  0.2931,  0.0483,  0.1324,  0.5577, -0.1947,  0.4666, -0.0600,\n",
              "          0.0784, -0.1828,  0.6205, -0.3140,  0.8450,  0.5443,  0.6414,  0.1618]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(64,324)\n",
        "\n"
      ],
      "metadata": {
        "id": "zn9DuHryBh7T"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model object for training\n",
        "model = SimpleRNN(len(vocab))\n",
        "\n"
      ],
      "metadata": {
        "id": "mNTp-02IFnvM"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "myBzgCJaE0Wb"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Loop**"
      ],
      "metadata": {
        "id": "l_1RidYnnfYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training loop\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question,answer in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(question)\n",
        "\n",
        "    loss = criterion(output,answer[0])\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}') # This is an total loss of epochs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8YFl69jE05t",
        "outputId": "3d8f38b7-869f-4d7f-8c16-4474ce42aea4"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 2.379574296043979\n",
            "Epoch 2/20, Loss: 1.0077966603140036\n",
            "Epoch 3/20, Loss: 0.8689027818540732\n",
            "Epoch 4/20, Loss: 0.7714404246459404\n",
            "Epoch 5/20, Loss: 0.6651000661568509\n",
            "Epoch 6/20, Loss: 0.5837660975754261\n",
            "Epoch 7/20, Loss: 0.48311413021551236\n",
            "Epoch 8/20, Loss: 0.4130003226714002\n",
            "Epoch 9/20, Loss: 0.35197212087611357\n",
            "Epoch 10/20, Loss: 0.3141734646012386\n",
            "Epoch 11/20, Loss: 0.2689311168984406\n",
            "Epoch 12/20, Loss: 0.22747464135496154\n",
            "Epoch 13/20, Loss: 0.19076458760537207\n",
            "Epoch 14/20, Loss: 0.16739897926131056\n",
            "Epoch 15/20, Loss: 0.14944415319090087\n",
            "Epoch 16/20, Loss: 0.12765893431432132\n",
            "Epoch 17/20, Loss: 0.11107314917414139\n",
            "Epoch 18/20, Loss: 0.0947904456846623\n",
            "Epoch 19/20, Loss: 0.08452641809255712\n",
            "Epoch 20/20, Loss: 0.07773717862760855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "djRTXEJUn8nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "\n",
        "  # convert question to numbers\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "\n",
        "  # tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # find index of max prob\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index])\n"
      ],
      "metadata": {
        "id": "DfviGILPGCoq"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"What is the capital of France?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPjY3fejSAUU",
        "outputId": "ce669cd9-5877-4ac1-f11f-b94c726ff0c0"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<UNK>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WKLJMYz9TK_J"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}