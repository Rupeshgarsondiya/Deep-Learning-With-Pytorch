{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "26d-AMd5LVUV",
        "outputId": "7cde85cd-026c-441f-c6bb-6aee73601508"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAuthor : Rupesh Garsondiya\\ngithub : @Rupeshgarsondiya\\nTopic  : Transfer Learning In CNN Using PyTorch\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "Author : Rupesh Garsondiya\n",
        "github : @Rupeshgarsondiya\n",
        "Topic  : Transfer Learning In CNN Using PyTorch\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning**\n",
        "\n",
        "**Reference :**PyTroch playlist By Nitish Sir (Campus X)\n",
        "\n",
        "**About This notebook :** You can gain practical knowledge on how to apply transfer learning in convolutional neural network using Torch.\n",
        "\n",
        "**prerequisites :**Understanding of CNN, Basic of torch, Transfer Learning\n",
        "\n",
        "**Suggestion :**If you want to understand how transfer learning in convolutional neural networks work, check out my deep learning repository. In that repo and check the file i give a file name **Trasfer_Learning_In_CNN-.ipynb** , I explain all deep learning concepts in detail with both theoretical and practical guides. Check it out!\n",
        "\n",
        "**Let's now focus on PyTorch**"
      ],
      "metadata": {
        "id": "9siBO7EJTm7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "!kaggle datasets download -d zalando-research/fashionmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0elFH6bSTbtZ",
        "outputId": "64a06952-c7bb-4217-949e-fe05f71397cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
            "License(s): other\n",
            "Downloading fashionmnist.zip to /content\n",
            " 96% 66.0M/68.8M [00:00<00:00, 255MB/s]\n",
            "100% 68.8M/68.8M [00:00<00:00, 230MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipfile = zipfile.ZipFile('/content/fashionmnist.zip')\n",
        "zipfile.extractall('/content')\n",
        "zipfile.close()"
      ],
      "metadata": {
        "id": "90yhHy2QWr8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import datasets, models, transforms\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaVKSDYkZaJ5",
        "outputId": "b2681a5d-c703-4eb2-8ba2-4055aaf5cbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7fc3ae7dc610>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('/content/fashion-mnist_train.csv')\n",
        "df_train.head()\n",
        "\n",
        "df_test = pd.read_csv('/content/fashion-mnist_test.csv')\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "5PY40e5WWxvc",
        "outputId": "7a9c8ace-dd86-474c-9c18-c442298ee3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      0       0       0       0       0       0       0       0       9   \n",
              "1      1       0       0       0       0       0       0       0       0   \n",
              "2      2       0       0       0       0       0       0      14      53   \n",
              "3      2       0       0       0       0       0       0       0       0   \n",
              "4      3       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0       8  ...       103        87        56         0         0         0   \n",
              "1       0  ...        34         0         0         0         0         0   \n",
              "2      99  ...         0         0         0         0        63        53   \n",
              "3       0  ...       137       126       140         0       133       224   \n",
              "4       0  ...         0         0         0         0         0         0   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0         0         0         0         0  \n",
              "1         0         0         0         0  \n",
              "2        31         0         0         0  \n",
              "3       222        56         0         0  \n",
              "4         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6e1cafe-04b4-49f7-976d-b1db8ec8bb41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>87</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>99</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>53</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>137</td>\n",
              "      <td>126</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6e1cafe-04b4-49f7-976d-b1db8ec8bb41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6e1cafe-04b4-49f7-976d-b1db8ec8bb41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6e1cafe-04b4-49f7-976d-b1db8ec8bb41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96710e68-969b-45f3-bc2b-e5a31c05877e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96710e68-969b-45f3-bc2b-e5a31c05877e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96710e68-969b-45f3-bc2b-e5a31c05877e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels for training set\n",
        "# X_train: All columns except 'label' from the df_train DataFrame are used as features for the training set\n",
        "# y_train: The 'label' column from df_train DataFrame is used as the target labels for the training set\n",
        "X_train = df_train.drop('label', axis=1).values\n",
        "y_train = df_train['label'].values\n",
        "\n",
        "# Extract features and labels for test set\n",
        "# X_test: All columns except 'label' from the df_test DataFrame are used as features for the test set\n",
        "# y_test: The 'label' column from df_test DataFrame is used as the target labels for the test set\n",
        "X_test = df_test.drop('label', axis=1).values\n",
        "y_test = df_test['label'].values\n",
        "\n",
        "# Print the shape (dimensions) of the training and testing data\n",
        "# This helps confirm the structure and size of the datasets\n",
        "print('X_train : ', X_train.shape)  # Prints the shape of the training features\n",
        "print('y_train : ', y_train.shape)  # Prints the shape of the training labels\n",
        "print('X_test : ', X_test.shape)    # Prints the shape of the test features\n",
        "print('y_test : ', y_test.shape)    # Prints the shape of the test labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2x9PDEFZHpl",
        "outputId": "a4ae049c-1cc7-4968-b67c-d0c0827b4b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train :  (60000, 784)\n",
            "y_train :  (60000,)\n",
            "X_test :  (10000, 784)\n",
            "y_test :  (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define the Transformation**\n",
        "\n",
        "Because in torchvision, they define what type of input is accepted by VGG16 or other models, you just need to check it out.\n",
        "\n",
        "**Supported input types and conventions :**\n",
        "Most transformations accept both PIL images and tensor inputs. Both CPU and CUDA tensors are supported. The result of both backends (PIL or Tensors) should be very close. In general, we recommend relying on the tensor backend for performance. The conversion transforms may be used to convert to and from PIL images, or for converting dtypes and ranges.\n",
        "\n",
        "Tensor image are expected to be of shape (C, H, W), where C is the number of channels, and H and W refer to height and width. Most transforms support batched tensor input. A batch of Tensor images is a tensor of shape (N, C, H, W), where N is a number of images in the batch. The v2 transforms generally accept an arbitrary number of leading dimensions (..., C, H, W) and can handle batched images or batched videos.\n",
        "\n",
        "**Reference :**https://pytorch.org/vision/main/transforms.html\n"
      ],
      "metadata": {
        "id": "BdTKQdPGqCxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Transformation\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "custom_transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.CenterCrop((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "RFBJK-4OebzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create CustomDataset class**"
      ],
      "metadata": {
        "id": "JZH3BK3brRAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,features,labels,transform):\n",
        "\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.transforms = transform\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    # resize images\n",
        "    image = self.features[index].reshape(28,28)\n",
        "\n",
        "    # convert datatype np.uint8\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    # chnage Gray Scale image to Colour image (RGB)\n",
        "    image = np.stack((image,)*3,axis=-1)  # set chennels like stack axis = -1 ===> (H,W,C) with out this parametr or default value ====> (C,H,W) --> Dimension Of the image\n",
        "\n",
        "    # convert array to PIL images\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    # applay transofrmation\n",
        "    image = self.transforms(image)\n",
        "\n",
        "    # return\n",
        "    return image,torch.tensor(self.labels[index])"
      ],
      "metadata": {
        "id": "-xyk_YC1c3Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,Dataset\n",
        "# create train dataset object\n",
        "train_dataset = CustomDataset(X_train,y_train,transform=custom_transform)\n",
        "\n",
        "\n",
        "# create test dataset object\n",
        "test_dataset = CustomDataset(X_test,y_test,custom_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size=8,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=8,shuffle=False)"
      ],
      "metadata": {
        "id": "YUW841ZIc8gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG16 Architechture**\n"
      ],
      "metadata": {
        "id": "gZumY2FNrfhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch pre-trained model\n",
        "'''\n",
        "1. Import the VGG16 model\n",
        "2. Freeze or No update in Feature part weight\n",
        "3. Create our own classifire part\n",
        "'''\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "print('='*20,'VGG16 Feature Part','='*20)\n",
        "print(vgg16.features)\n",
        "print('='*20,'VGG16 Classifier Part','='*20)\n",
        "print(vgg16.classifier)\n",
        "\n",
        "# Freeze the Weight\n",
        "for param in vgg16.features.parameters():  # we fetch all the parameter for the feature part and set required_gread = Fale  it mean during training no gradient update\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "# Chnage the classifire part of the VGG16\n",
        "vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=25088, out_features=1024, bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.5, inplace=False),\n",
        "    nn.Linear(in_features=512, out_features=10, bias=True)\n",
        ")\n",
        "\n",
        "print('='*20,'Own Classifier Part','='*20)\n",
        "print(vgg16.classifier)\n",
        "\n",
        "\n",
        "# Model move on GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16 = vgg16.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1veW_h9jRTc",
        "outputId": "d11d8ff4-dcfb-4063-e2d3-9f252c1c84d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== VGG16 Feature Part ====================\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU(inplace=True)\n",
            "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (25): ReLU(inplace=True)\n",
            "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (27): ReLU(inplace=True)\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "==================== VGG16 Classifier Part ====================\n",
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            ")\n",
            "==================== Own Classifier Part ====================\n",
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "TN0bzQM1lgHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16.classifier.parameters(),lr=learning_rate) # optimizer only perform on the classifire part of the architechture"
      ],
      "metadata": {
        "id": "cmVEJixklcVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Training Loop**"
      ],
      "metadata": {
        "id": "cJMC0SFEexw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# Iterate through the specified number of epochs\n",
        "for epochs in range(epochs):\n",
        "\n",
        "    # Initialize variable to track total loss for this epoch\n",
        "    total_epochs_loss = 0\n",
        "\n",
        "    # Iterate through each batch of data in the train_loader (this handles batching and shuffling of the data)\n",
        "    for batch_feature, label in train_loader:\n",
        "\n",
        "        batch_feature = batch_feature.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass: Pass the batch of features through the model to get the predictions (output)\n",
        "        output = vgg16(batch_feature)\n",
        "\n",
        "        # Calculate the loss between the predicted output and true labels\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        # Add the current loss to the total loss for the epoch\n",
        "        total_epochs_loss += loss.item()\n",
        "\n",
        "        # Backward pass: Compute gradients of the loss with respect to model parameters\n",
        "        optimizer.zero_grad()  # Clear the previous gradients\n",
        "        loss.backward()        # Backpropagate the loss to compute new gradients\n",
        "\n",
        "        # Update model parameters (weights and biases) using the optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate the average loss for the epoch (divide by the number of batches in the train_loader)\n",
        "    avg_loss = total_epochs_loss / len(train_loader)\n",
        "\n",
        "    # Print the average loss for the current epoch\n",
        "    print(f'Epoch : {epochs+1} Loss : {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEmnA7Nkegxl",
        "outputId": "7baaade3-4be9-454b-b127-b42131677957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 Loss : 2.5410263346791266\n",
            "Epoch : 2 Loss : 2.6241194193045296\n",
            "Epoch : 3 Loss : 2.718522989622752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **No changes in the Inference code**"
      ],
      "metadata": {
        "id": "JXIp93njtocD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set model to eval mode\n",
        "# we need to define our model explicitly you use as evalulate beacuse in deep leaarning some time behave diffrent during training and testing\n",
        "# like dropout we fropout apply on only during traing we not apply dropout on testing\n",
        "# same in case of the batch normalization\n",
        "\n",
        "vgg16.eval()\n",
        "\n",
        "# Evaluation code: Evaluates the model on the test set\n",
        "\n",
        "# Initialize variables to track the total number of samples and number of correct predictions\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "# Disable gradient calculation to save memory and computation during evaluation\n",
        "# `torch.no_grad()` ensures that gradients are not calculated during this phase\n",
        "with torch.no_grad():\n",
        "\n",
        "  # Iterate through each batch in the test_loader (this handles batching of test data)\n",
        "  for batch_feature, label in test_loader:\n",
        "\n",
        "    batch_feature = batch_feature.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Forward pass: Pass the batch of test features through the model to get the predictions (output)\n",
        "    output = vgg16(batch_feature)\n",
        "\n",
        "    # Get the predicted class by selecting the index with the highest output score for each sample\n",
        "    # `torch.max(output, 1)` returns the maximum value and its index along dimension 1 (the classes)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    # Update the total number of samples\n",
        "    total = total + label.size(0)\n",
        "\n",
        "    # Update the number of correct predictions by comparing predicted classes with actual labels\n",
        "    correct = correct + (predicted == label).sum().item()\n",
        "\n",
        "# Calculate and print the accuracy as the ratio of correct predictions to the total number of samples\n",
        "print(f'Accuracy : {correct/total}')"
      ],
      "metadata": {
        "id": "yIHyCWx9etx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9ad2a5bf-9b06-4e7c-aa2b-229ef2d93525"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vgg16' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6a4662bb7a8a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# same in case of the batch normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Evaluation code: Evaluates the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vgg16' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScLVgxRTzJv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}